{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem root is ./data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/rokickik/dev/ngffbrowse/data/test.h5j',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/N2_352-1.n5',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/Untitled1.ipynb',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/.DS_Store',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/state.json',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/MAX_NP01_5_1_SS00790_sNPF_546_Crz_647_1x_LOL.jpg',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/out2.json',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/mobie',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/.ipynb_checkpoints',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/bioformats2raw_versions.yml',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/n5_ANM525849',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/out.json',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/N2_352-1.zarr',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/serve.sh',\n",
       " '/Users/rokickik/dev/ngffbrowse/data/single.json']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fsspec\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def get_fs(url):\n",
    "    pu = urlparse(url)\n",
    "    if pu.scheme in ['http','https'] and pu.netloc.endswith('.s3.amazonaws.com'):\n",
    "        # Convert S3 HTTP URLs (which do not support list operations) back to S3 REST API\n",
    "        fs = fsspec.filesystem('s3')\n",
    "        p = pu.netloc.split('.')[0] + pu.path\n",
    "    else:\n",
    "        fs = fsspec.filesystem(pu.scheme)\n",
    "        p = pu.netloc + pu.path\n",
    "    return fs, p\n",
    "\n",
    "url1 = \"./data\"\n",
    "fs1, fs1root = get_fs(url1)\n",
    "print(f\"Filesystem root is {fs1root}\")\n",
    "fs1.ls(fs1root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Key': 'janelia-flylight-imagery-dev/Fly-eFISH/',\n",
       "  'LastModified': datetime.datetime(2024, 2, 23, 15, 40, 52, tzinfo=tzutc()),\n",
       "  'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       "  'Size': 0,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'type': 'file',\n",
       "  'size': 0,\n",
       "  'name': 'janelia-flylight-imagery-dev/Fly-eFISH/'},\n",
       " {'Key': 'janelia-flylight-imagery-dev/Fly-eFISH/NP01_1_1_SS00790.json',\n",
       "  'LastModified': datetime.datetime(2024, 2, 29, 20, 59, 29, tzinfo=tzutc()),\n",
       "  'ETag': '\"eb8fd5db7b1bfdba7c3a076f23ed9643\"',\n",
       "  'Size': 3459,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'type': 'file',\n",
       "  'size': 3459,\n",
       "  'name': 'janelia-flylight-imagery-dev/Fly-eFISH/NP01_1_1_SS00790.json'},\n",
       " {'Key': 'janelia-flylight-imagery-dev/Fly-eFISH/state.json',\n",
       "  'LastModified': datetime.datetime(2024, 2, 28, 20, 32, 8, tzinfo=tzutc()),\n",
       "  'ETag': '\"7db26713fa2b049c3508145aed6dfec4\"',\n",
       "  'Size': 1101,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'type': 'file',\n",
       "  'size': 1101,\n",
       "  'name': 'janelia-flylight-imagery-dev/Fly-eFISH/state.json'},\n",
       " {'Key': 'janelia-flylight-imagery-dev/Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.chunked.zarr',\n",
       "  'Size': 0,\n",
       "  'StorageClass': 'DIRECTORY',\n",
       "  'type': 'directory',\n",
       "  'size': 0,\n",
       "  'name': 'janelia-flylight-imagery-dev/Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.chunked.zarr'},\n",
       " {'Key': 'janelia-flylight-imagery-dev/Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr',\n",
       "  'Size': 0,\n",
       "  'StorageClass': 'DIRECTORY',\n",
       "  'type': 'directory',\n",
       "  'size': 0,\n",
       "  'name': 'janelia-flylight-imagery-dev/Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = \"s3://janelia-flylight-imagery-dev/Fly-eFISH\"\n",
    "fs2, fs2root = get_fs(url2)\n",
    "fs2.ls(fs2root, detail=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = \"https://janelia-flylight-imagery-dev.s3.amazonaws.com/Fly-eFISH\"\n",
    "fs2, fs2root = get_fs(url2)\n",
    "len(fs2.ls(fs2root, detail=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Key': 'janelia-flylight-imagery-dev/Fly-eFISH/state.json',\n",
       " 'LastModified': datetime.datetime(2024, 2, 28, 20, 32, 8, tzinfo=tzutc()),\n",
       " 'ETag': '\"7db26713fa2b049c3508145aed6dfec4\"',\n",
       " 'Size': 1101,\n",
       " 'StorageClass': 'STANDARD',\n",
       " 'type': 'file',\n",
       " 'size': 1101,\n",
       " 'name': 'janelia-flylight-imagery-dev/Fly-eFISH/state.json'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = \"https://janelia-flylight-imagery-dev.s3.amazonaws.com/Fly-eFISH/state.json\"\n",
    "fs2, fs2root = get_fs(url2)\n",
    "fs2.info(fs2root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'file',\n",
       " 'local',\n",
       " 'memory',\n",
       " 'dropbox',\n",
       " 'http',\n",
       " 'https',\n",
       " 'zip',\n",
       " 'tar',\n",
       " 'gcs',\n",
       " 'gs',\n",
       " 'gdrive',\n",
       " 'sftp',\n",
       " 'ssh',\n",
       " 'ftp',\n",
       " 'hdfs',\n",
       " 'arrow_hdfs',\n",
       " 'webhdfs',\n",
       " 's3',\n",
       " 's3a',\n",
       " 'wandb',\n",
       " 'oci',\n",
       " 'ocilake',\n",
       " 'asynclocal',\n",
       " 'adl',\n",
       " 'abfs',\n",
       " 'az',\n",
       " 'cached',\n",
       " 'blockcache',\n",
       " 'filecache',\n",
       " 'simplecache',\n",
       " 'dask',\n",
       " 'dbfs',\n",
       " 'github',\n",
       " 'git',\n",
       " 'smb',\n",
       " 'jupyter',\n",
       " 'jlab',\n",
       " 'libarchive',\n",
       " 'reference',\n",
       " 'generic',\n",
       " 'oss',\n",
       " 'webdav',\n",
       " 'dvc',\n",
       " 'hf',\n",
       " 'root',\n",
       " 'dir',\n",
       " 'box',\n",
       " 'lakefs']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://filesystem-spec.readthedocs.io/en/latest/api.html#implementations\n",
    "fsspec.available_protocols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Access S3 as if it were a file system.\n",
      "\n",
      "    This exposes a filesystem-like API (ls, cp, open, etc.) on top of S3\n",
      "    storage.\n",
      "\n",
      "    Provide credentials either explicitly (``key=``, ``secret=``) or depend\n",
      "    on boto's credential methods. See botocore documentation for more\n",
      "    information. If no credentials are available, use ``anon=True``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    anon : bool (False)\n",
      "        Whether to use anonymous connection (public buckets only). If False,\n",
      "        uses the key/secret given, or boto's credential resolver (client_kwargs,\n",
      "        environment, variables, config files, EC2 IAM server, in that order)\n",
      "    endpoint_url : string (None)\n",
      "        Use this endpoint_url, if specified. Needed for connecting to non-AWS\n",
      "        S3 buckets. Takes precedence over `endpoint_url` in client_kwargs.\n",
      "    key : string (None)\n",
      "        If not anonymous, use this access key ID, if specified. Takes precedence\n",
      "        over `aws_access_key_id` in client_kwargs.\n",
      "    secret : string (None)\n",
      "        If not anonymous, use this secret access key, if specified. Takes\n",
      "        precedence over `aws_secret_access_key` in client_kwargs.\n",
      "    token : string (None)\n",
      "        If not anonymous, use this security token, if specified\n",
      "    use_ssl : bool (True)\n",
      "        Whether to use SSL in connections to S3; may be faster without, but\n",
      "        insecure. If ``use_ssl`` is also set in ``client_kwargs``,\n",
      "        the value set in ``client_kwargs`` will take priority.\n",
      "    s3_additional_kwargs : dict of parameters that are used when calling s3 api\n",
      "        methods. Typically used for things like \"ServerSideEncryption\".\n",
      "    client_kwargs : dict of parameters for the botocore client\n",
      "    requester_pays : bool (False)\n",
      "        If RequesterPays buckets are supported.\n",
      "    default_block_size: int (None)\n",
      "        If given, the default block size value used for ``open()``, if no\n",
      "        specific value is given at all time. The built-in default is 5MB.\n",
      "    default_fill_cache : Bool (True)\n",
      "        Whether to use cache filling with open by default. Refer to\n",
      "        ``S3File.open``.\n",
      "    default_cache_type : string (\"readahead\")\n",
      "        If given, the default cache_type value used for ``open()``. Set to \"none\"\n",
      "        if no caching is desired. See fsspec's documentation for other available\n",
      "        cache_type values. Default cache_type is \"readahead\".\n",
      "    version_aware : bool (False)\n",
      "        Whether to support bucket versioning.  If enable this will require the\n",
      "        user to have the necessary IAM permissions for dealing with versioned\n",
      "        objects. Note that in the event that you only need to work with the\n",
      "        latest version of objects in a versioned bucket, and do not need the\n",
      "        VersionId for those objects, you should set ``version_aware`` to False\n",
      "        for performance reasons. When set to True, filesystem instances will\n",
      "        use the S3 ListObjectVersions API call to list directory contents,\n",
      "        which requires listing all historical object versions.\n",
      "    cache_regions : bool (False)\n",
      "        Whether to cache bucket regions or not. Whenever a new bucket is used,\n",
      "        it will first find out which region it belongs and then use the client\n",
      "        for that region.\n",
      "    asynchronous :  bool (False)\n",
      "        Whether this instance is to be used from inside coroutines.\n",
      "    config_kwargs : dict of parameters passed to ``botocore.client.Config``\n",
      "    kwargs : other parameters for core session.\n",
      "    session : aiobotocore AioSession object to be used for all connections.\n",
      "         This session will be used inplace of creating a new session inside S3FileSystem.\n",
      "         For example: aiobotocore.session.AioSession(profile='test_user')\n",
      "\n",
      "    The following parameters are passed on to fsspec:\n",
      "\n",
      "    skip_instance_cache: to control reuse of instances\n",
      "    use_listings_cache, listings_expiry_time, max_paths: to control reuse of directory listings\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> s3 = S3FileSystem(anon=False)  # doctest: +SKIP\n",
      "    >>> s3.ls('my-bucket/')  # doctest: +SKIP\n",
      "    ['my-file.txt']\n",
      "\n",
      "    >>> with s3.open('my-bucket/my-file.txt', mode='rb') as f:  # doctest: +SKIP\n",
      "    ...     print(f.read())  # doctest: +SKIP\n",
      "    b'Hello, world!'\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(fsspec.get_filesystem_class(\"s3\").__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N5 N2_352-1.n5\n",
      "        N5 ARRAY N2_352-1.n5/image/c0/s0\n",
      "  bioformats2raw series NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr\n",
      "    ZARR MULTISCALE NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0\n",
      "      ZARR ARRAY NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0/0\n",
      "      ZARR ARRAY NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0/1\n",
      "      ZARR ARRAY NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0/3\n",
      "      ZARR ARRAY NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0/2\n",
      "  N5 n5_ANM525849\n",
      "    N5 MULTISCALE n5_ANM525849/c0\n",
      "      N5 ARRAY n5_ANM525849/c0/s2\n",
      "      N5 ARRAY n5_ANM525849/c0/s1\n",
      "      N5 ARRAY n5_ANM525849/c0/s0\n",
      "    N5 MULTISCALE n5_ANM525849/c1\n",
      "      N5 ARRAY n5_ANM525849/c1/s2\n",
      "      N5 ARRAY n5_ANM525849/c1/s1\n",
      "      N5 ARRAY n5_ANM525849/c1/s0\n",
      "    ZARR MULTISCALE N2_352-1.zarr/image\n",
      "      ZARR ARRAY N2_352-1.zarr/image/s0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_ngff(fs, root, path, depth=0):\n",
    "    if depth>10: return []\n",
    "    indent = depth * '  '\n",
    "    #name = os.path.basename(path)\n",
    "    name = os.path.relpath(path, start=root)\n",
    "    #print(indent+path+\" \"+name)\n",
    "    children = fs.ls(path, detail=True)\n",
    "    child_names = [os.path.basename(c['name']) for c in children]\n",
    "    if '.zattrs' in child_names:\n",
    "        with fsspec.open(path+'/.zattrs') as f:\n",
    "            attrs = json.load(f)\n",
    "            if 'multiscales' in attrs:\n",
    "                print(indent+'ZARR MULTISCALE '+name)\n",
    "            if 'bioformats2raw.layout' in attrs:\n",
    "                print(indent+'bioformats2raw series '+name)\n",
    "\n",
    "    if '.zarray' in child_names:\n",
    "        print(indent+'ZARR ARRAY '+name)\n",
    "        return\n",
    "    \n",
    "    if 'attributes.json' in child_names:\n",
    "        with fsspec.open(path+'/attributes.json') as f:\n",
    "            attrs = json.load(f)\n",
    "            if 'scales' in attrs:\n",
    "                print(indent+'N5 MULTISCALE '+name)\n",
    "            elif 'dimensions' in attrs:\n",
    "                print(indent+'N5 ARRAY '+name)\n",
    "                return\n",
    "            elif 'n5' in attrs:\n",
    "                #re.match(\"^c\\d+$\", \"cf\")\n",
    "\n",
    "                print(indent+'N5 '+name)\n",
    "\n",
    "    for d in [i['name'] for i in children if i['type']=='directory']:\n",
    "        find_ngff(fs, root, d, depth+1)\n",
    "        \n",
    "find_ngff(fs1, fs1root, fs1root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union, Optional, Any, Dict, Literal\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  bioformats2raw series NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr\n",
      "    ZARR MULTISCALE NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0\n",
      "      ZARR ARRAY NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0/0\n",
      "      ZARR ARRAY NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0/1\n",
      "      ZARR ARRAY NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0/3\n",
      "      ZARR ARRAY NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0/2\n",
      "    ZARR MULTISCALE N2_352-1.zarr/image\n",
      "      ZARR ARRAY N2_352-1.zarr/image/s0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_ome_zarrs(fs, root, path, depth=0):\n",
    "    if depth>10: return []\n",
    "    indent = depth * '  '\n",
    "    name = os.path.relpath(path, start=root)\n",
    "    children = fs.ls(path, detail=True)\n",
    "    child_names = [os.path.basename(c['name']) for c in children]\n",
    "    if '.zattrs' in child_names:\n",
    "        with fsspec.open(path+'/.zattrs') as f:\n",
    "            attrs = json.load(f)\n",
    "            if 'multiscales' in attrs:\n",
    "                print(indent+'ZARR MULTISCALE '+name)\n",
    "            if 'bioformats2raw.layout' in attrs:\n",
    "                print(indent+'bioformats2raw series '+name)\n",
    "\n",
    "    if '.zarray' in child_names:\n",
    "        print(indent+'ZARR ARRAY '+name)\n",
    "        return\n",
    "    \n",
    "\n",
    "    for d in [i['name'] for i in children if i['type']=='directory']:\n",
    "        find_ome_zarrs(fs, root, d, depth+1)\n",
    "        \n",
    "find_ome_zarrs(fs1, fs1root, fs1root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<Error><Code>NoSuchKey</Code><Message>The specified key does not exist.</Message><Key>Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.chunked.zarr/0/labels/.zattrs</Key><RequestId>JMPQ1066EVC7NQVY</RequestId><HostId>MYYlrY4+RSd8W5oLgypv4YP7T5G4V6nBoDL9sHFmIxdZVumSGudtAKW4COr18AFnbb1Fc5bBjVg36oDxHXqLCw==</HostId></Error>\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjects.html#API_ListObjects_ResponseSyntax\"\n",
    "\n",
    "\"Content-Type: binary/octet-stream\"\n",
    "\n",
    "\"\"\"\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<Error><Code>NoSuchKey</Code><Message>The specified key does not exist.</Message><Key>Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.chunked.zarr/0/labels/.zattrs</Key><RequestId>JMPQ1066EVC7NQVY</RequestId><HostId>MYYlrY4+RSd8W5oLgypv4YP7T5G4V6nBoDL9sHFmIxdZVumSGudtAKW4COr18AFnbb1Fc5bBjVg36oDxHXqLCw==</HostId></Error>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image(id='01', path='./data/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0', axes='TCZYX', num_channels=4, num_timepoints=1, dimensions='1 ✕ 4 ✕ 376.00 μm ✕ 447.29 μm ✕ 447.29 μm', dimensions_voxels='1 ✕ 4 ✕ 752 ✕ 1920 ✕ 1920', chunk_size='1 ✕ 1 ✕ 1 ✕ 1920 ✕ 1920', voxel_sizes='1 ✕ 1 ✕ 0.50 μm ✕ 0.23 μm ✕ 0.23 μm', compression=\"Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Image(BaseModel):\n",
    "    model_config = ConfigDict(extra='forbid') \n",
    "    id: str = Field(title=\"Id\", description=\"Id for the data set container (unique within the parent folder)\")\n",
    "    path: str = Field(title=\"Path\", description=\"Path to the container, relative to the overall root\")\n",
    "    axes: str = Field(title=\"Axes\", description=\"Axes \")\n",
    "    num_channels: int = Field(title=\"Num Channels\", description=\"Number of channels in the image\")\n",
    "    num_timepoints: int = Field(title=\"Num Timepoints\", description=\"Number of timepoints in the image\")\n",
    "    dimensions: str = Field(title=\"Dimensions\", description=\"Size of the whole data set in nanometers\")\n",
    "    dimensions_voxels: str = Field(title=\"Dimensions (voxels)\", description=\"Size of the whole data set in voxels\")\n",
    "    chunk_size: str = Field(title=\"Chunk size\", description=\"Size of Zarr chunks\")\n",
    "    voxel_sizes: str = Field(title=\"Voxel Size\", description=\"Size of voxels in nanometers. XYZ ordering.\")\n",
    "    compression: str = Field(title=\"Compression\", description=\"Description of the compression used on the image data\")\n",
    "\n",
    "\n",
    "def encode_image(id, url, image_group):\n",
    "    multiscales = image_group.attrs['multiscales']\n",
    "    # TODO: what to do if there are multiple multiscales?\n",
    "    multiscale = multiscales[0]\n",
    "    axes = multiscale['axes']\n",
    "\n",
    "    # Use highest resolution \n",
    "    dataset = multiscale['datasets'][0]\n",
    "    array = image_group[image_group.name+'/'+dataset['path']]\n",
    "    \n",
    "    # TODO: shouldn't assume a single transform\n",
    "    scale = dataset['coordinateTransformations'][0]['scale']\n",
    "\n",
    "    axes_names = []\n",
    "    dimensions_voxels = []\n",
    "    voxel_sizes = []\n",
    "    dimensions = []\n",
    "    chunks = []\n",
    "    num_channels = 1\n",
    "    num_timepoints = 1\n",
    "    for i, axis in enumerate(axes):\n",
    "        axes_names.append(axis['name'].upper())\n",
    "        unit = ''\n",
    "        if axis['type']=='space':\n",
    "            unit = axis['unit']\n",
    "            if unit=='micrometer': unit = \" μm\"\n",
    "            if unit=='nanometer': unit = \" nm\"\n",
    "            voxel_sizes.append(\"%.2f%s\" % (round(scale[i],2), unit))\n",
    "            dimensions.append(\"%.2f%s\" % (round(array.shape[i] * scale[i],2), unit))\n",
    "        elif axis['type']=='channel':\n",
    "            num_channels = array.shape[i]\n",
    "            voxel_sizes.append(\"%i\" % scale[i])\n",
    "            dimensions.append(\"%i\" % (array.shape[i] * scale[i]))\n",
    "        elif axis['type']=='time':\n",
    "            num_timepoints = array.shape[i]\n",
    "            voxel_sizes.append(\"%i\" % scale[i])\n",
    "            dimensions.append(\"%i\" % (array.shape[i] * scale[i]))\n",
    "        dimensions_voxels.append(str(array.shape[i]))\n",
    "        chunks.append(\"%i\" % array.chunks[i])\n",
    "\n",
    "    return Image(\n",
    "        id = id,\n",
    "        path = url,\n",
    "        axes = ''.join(axes_names),\n",
    "        num_channels = num_channels,\n",
    "        num_timepoints = num_timepoints,\n",
    "        voxel_sizes = ' ✕ '.join(voxel_sizes),\n",
    "        dimensions = ' ✕ '.join(dimensions),\n",
    "        dimensions_voxels = ' ✕ '.join(dimensions_voxels),\n",
    "        chunk_size = ' ✕ '.join(chunks),\n",
    "        compression = str(array.compressor)\n",
    "    )\n",
    "\n",
    "import zarr\n",
    "url = \"./data/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr/0\"\n",
    "z = zarr.open(url, mode='r')\n",
    "\n",
    "image = encode_image('01', url, z)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting images from ./data/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr\n",
      "Image(id='./data/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr', path='./data/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr', axes='TCZYX', num_channels=4, num_timepoints=1, dimensions='1 ✕ 4 ✕ 376.00 μm ✕ 447.29 μm ✕ 447.29 μm', dimensions_voxels='1 ✕ 4 ✕ 752 ✕ 1920 ✕ 1920', chunk_size='1 ✕ 1 ✕ 1 ✕ 1920 ✕ 1920', voxel_sizes='1 ✕ 1 ✕ 0.50 μm ✕ 0.23 μm ✕ 0.23 μm', compression=\"Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\")\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import zarr\n",
    "    \n",
    "def yield_images_nested(z):\n",
    "    # This only works with storage backends that support listing items like \n",
    "    # local disk and S3, but not HTTP for example.\n",
    "    for _,group in z.groups():\n",
    "        if 'multiscales' in group.attrs:\n",
    "            yield group\n",
    "        for image in yield_images_nested(group):\n",
    "            yield image\n",
    "\n",
    "def yield_images(url):\n",
    "    ''' Interrogates the OME-Zarr at the given URL and yields all of the 2-5D images within.\n",
    "    '''\n",
    "    z = zarr.open(url, mode='r')\n",
    "    # Based on https://ngff.openmicroscopy.org/latest/#bf2raw\n",
    "    if 'bioformats2raw.layout' in z.attrs and z.attrs['bioformats2raw.layout']==3:\n",
    "        if 'OME' in z:\n",
    "            series = z['OME'].attrs['series']\n",
    "            if len(series) == 1:\n",
    "                # We treat this as a single image for easier consumption\n",
    "                yield z[series[0]]\n",
    "            else:\n",
    "                # Spec: \"series\" MUST be a list of string objects, each of which is a path to an image group.\n",
    "                for image_id in series:\n",
    "                    yield z[image_id]\n",
    "        else:\n",
    "            # Spec: If the \"series\" attribute does not exist and no \"plate\" is present:\n",
    "            # - separate \"multiscales\" images MUST be stored in consecutively numbered groups starting from 0 (i.e. \"0/\", \"1/\", \"2/\", \"3/\", ...).\n",
    "            for i in itertools.count():\n",
    "                try:\n",
    "                    yield z[str(i)]\n",
    "                except:\n",
    "                    break\n",
    "    elif 'multiscales' in z.attrs:\n",
    "        yield z\n",
    "    else:\n",
    "        for image in yield_images_nested(z):\n",
    "            yield image\n",
    "\n",
    "def get_images(url):\n",
    "    print(f\"Getting images from {url}\")\n",
    "    for image_group in yield_images(url):\n",
    "        image = encode_image(url, url, image_group)\n",
    "        print(image.__repr__())\n",
    "\n",
    "\n",
    "url = \"./data/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.czi.zarr\"\n",
    "get_images(url)\n",
    "#%timeit get_images(url)\n",
    "#812 µs ± 11 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting images from https://janelia-flylight-imagery-dev.s3.amazonaws.com/Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.chunked.zarr\n",
      "Image(id='https://janelia-flylight-imagery-dev.s3.amazonaws.com/Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.chunked.zarr', path='https://janelia-flylight-imagery-dev.s3.amazonaws.com/Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.chunked.zarr', axes='TCZYX', num_channels=4, num_timepoints=1, dimensions='1 ✕ 4 ✕ 376.00 μm ✕ 447.29 μm ✕ 447.29 μm', dimensions_voxels='1 ✕ 4 ✕ 752 ✕ 1920 ✕ 1920', chunk_size='1 ✕ 1 ✕ 128 ✕ 128 ✕ 128', voxel_sizes='1 ✕ 1 ✕ 0.50 μm ✕ 0.23 μm ✕ 0.23 μm', compression=\"Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://janelia-flylight-imagery-dev.s3.amazonaws.com/Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.chunked.zarr\"\n",
    "get_images(url)\n",
    "#%timeit get_images(url)\n",
    "#365 ms ± 51.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zarr.open(url, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channels': [{'color': '00FF00',\n",
       "   'coefficient': 1,\n",
       "   'active': True,\n",
       "   'label': 'Cam1-T1',\n",
       "   'window': {'min': 40.0, 'max': 51986.0, 'start': 40.0, 'end': 51986.0},\n",
       "   'family': 'linear',\n",
       "   'inverted': False},\n",
       "  {'color': 'FF00FF',\n",
       "   'coefficient': 1,\n",
       "   'active': True,\n",
       "   'label': 'Cam2-T1',\n",
       "   'window': {'min': 52.0, 'max': 16528.0, 'start': 52.0, 'end': 16528.0},\n",
       "   'family': 'linear',\n",
       "   'inverted': False},\n",
       "  {'color': 'FF0000',\n",
       "   'coefficient': 1,\n",
       "   'active': True,\n",
       "   'label': 'Cam2-T2',\n",
       "   'window': {'min': 62.0, 'max': 32500.0, 'start': 62.0, 'end': 32500.0},\n",
       "   'family': 'linear',\n",
       "   'inverted': False},\n",
       "  {'color': '00FFFF',\n",
       "   'coefficient': 1,\n",
       "   'active': False,\n",
       "   'label': 'Cam1-T3',\n",
       "   'window': {'min': 78.0, 'max': 9636.0, 'start': 78.0, 'end': 9636.0},\n",
       "   'family': 'linear',\n",
       "   'inverted': False}],\n",
       " 'rdefs': {'defaultT': 0, 'model': 'color', 'defaultZ': 376}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z['0'].attrs['omero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rokickik/opt/anaconda3/envs/ngffbrowse/lib/python3.10/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.generics:GenericModel` has been moved to `pydantic.BaseModel`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "19 validation errors for ViewerState\nposition\n  Tuple should have at most 3 items after validation, not 4 [type=too_long, input_value=[396, 912, 976, 0], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.6/v/too_long\nlayers.0.image.shaderControls.normalized.float\n  Input should be a valid number [type=float_type, input_value={'range': [185, 5032]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/float_type\nlayers.0.image.shaderControls.normalized.InvlerpParameters.window\n  Field required [type=missing, input_value={'range': [185, 5032]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nlayers.0.image.localDimensions\n  Extra inputs are not permitted [type=extra_forbidden, input_value={\"c'\": [1, '']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.0.image.localPosition\n  Extra inputs are not permitted [type=extra_forbidden, input_value=[0], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.1.image.shaderControls.hue.float\n  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='#6dff44', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.6/v/float_parsing\nlayers.1.image.shaderControls.hue.InvlerpParameters\n  Input should be a valid dictionary or instance of InvlerpParameters [type=model_type, input_value='#6dff44', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.6/v/model_type\nlayers.1.image.shaderControls.normalized.float\n  Input should be a valid number [type=float_type, input_value={'range': [199, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/float_type\nlayers.1.image.shaderControls.normalized.InvlerpParameters.window\n  Field required [type=missing, input_value={'range': [199, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nlayers.1.image.localDimensions\n  Extra inputs are not permitted [type=extra_forbidden, input_value={\"c'\": [1, '']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.1.image.localPosition\n  Extra inputs are not permitted [type=extra_forbidden, input_value=[1], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.2.image.shaderControls.normalized.float\n  Input should be a valid number [type=float_type, input_value={'range': [212, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/float_type\nlayers.2.image.shaderControls.normalized.InvlerpParameters.window\n  Field required [type=missing, input_value={'range': [212, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nlayers.2.image.localDimensions\n  Extra inputs are not permitted [type=extra_forbidden, input_value={\"c'\": [1, '']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.2.image.localPosition\n  Extra inputs are not permitted [type=extra_forbidden, input_value=[2], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.3.image.shaderControls.normalized.float\n  Input should be a valid number [type=float_type, input_value={'range': [133, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/float_type\nlayers.3.image.shaderControls.normalized.InvlerpParameters.window\n  Field required [type=missing, input_value={'range': [133, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nlayers.3.image.localDimensions\n  Extra inputs are not permitted [type=extra_forbidden, input_value={\"c'\": [1, '']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.3.image.localPosition\n  Extra inputs are not permitted [type=extra_forbidden, input_value=[3], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     state_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m----> 6\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mViewerState\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstate_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m state\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ngffbrowse/lib/python3.10/site-packages/pydantic/main.py:171\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    170\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 19 validation errors for ViewerState\nposition\n  Tuple should have at most 3 items after validation, not 4 [type=too_long, input_value=[396, 912, 976, 0], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.6/v/too_long\nlayers.0.image.shaderControls.normalized.float\n  Input should be a valid number [type=float_type, input_value={'range': [185, 5032]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/float_type\nlayers.0.image.shaderControls.normalized.InvlerpParameters.window\n  Field required [type=missing, input_value={'range': [185, 5032]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nlayers.0.image.localDimensions\n  Extra inputs are not permitted [type=extra_forbidden, input_value={\"c'\": [1, '']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.0.image.localPosition\n  Extra inputs are not permitted [type=extra_forbidden, input_value=[0], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.1.image.shaderControls.hue.float\n  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='#6dff44', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.6/v/float_parsing\nlayers.1.image.shaderControls.hue.InvlerpParameters\n  Input should be a valid dictionary or instance of InvlerpParameters [type=model_type, input_value='#6dff44', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.6/v/model_type\nlayers.1.image.shaderControls.normalized.float\n  Input should be a valid number [type=float_type, input_value={'range': [199, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/float_type\nlayers.1.image.shaderControls.normalized.InvlerpParameters.window\n  Field required [type=missing, input_value={'range': [199, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nlayers.1.image.localDimensions\n  Extra inputs are not permitted [type=extra_forbidden, input_value={\"c'\": [1, '']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.1.image.localPosition\n  Extra inputs are not permitted [type=extra_forbidden, input_value=[1], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.2.image.shaderControls.normalized.float\n  Input should be a valid number [type=float_type, input_value={'range': [212, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/float_type\nlayers.2.image.shaderControls.normalized.InvlerpParameters.window\n  Field required [type=missing, input_value={'range': [212, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nlayers.2.image.localDimensions\n  Extra inputs are not permitted [type=extra_forbidden, input_value={\"c'\": [1, '']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.2.image.localPosition\n  Extra inputs are not permitted [type=extra_forbidden, input_value=[2], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.3.image.shaderControls.normalized.float\n  Input should be a valid number [type=float_type, input_value={'range': [133, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/float_type\nlayers.3.image.shaderControls.normalized.InvlerpParameters.window\n  Field required [type=missing, input_value={'range': [133, 4122]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nlayers.3.image.localDimensions\n  Extra inputs are not permitted [type=extra_forbidden, input_value={\"c'\": [1, '']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden\nlayers.3.image.localPosition\n  Extra inputs are not permitted [type=extra_forbidden, input_value=[3], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydantic_neuroglancer.viewer_state import ViewerState\n",
    "\n",
    "with open('state.json', 'r') as f:\n",
    "    state_json = json.load(f)\n",
    "    state = ViewerState(**state_json)\n",
    "\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimensions': {'z': [5e-07, 'm'],\n",
       "  'y': [2.329612336924942e-07, 'm'],\n",
       "  'x': [2.329612336924942e-07, 'm'],\n",
       "  't': [1.0, '']},\n",
       " 'position': [396.0, 912.0, 976.0, 0.0],\n",
       " 'crossSectionScale': 4.687971627022003,\n",
       " 'projectionScale': 2048.0,\n",
       " 'layers': [{'type': 'image',\n",
       "   'source': [{'url': 'zarr://s3://janelia-flylight-imagery-dev/Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.chunked.zarr/0'}],\n",
       "   'localDimensions': {\"c'\": [1.0, '']},\n",
       "   'localPosition': [0.0],\n",
       "   'tab': 'rendering',\n",
       "   'opacity': 1.0,\n",
       "   'blend': 'additive',\n",
       "   'shader': '#uicontrol vec3 hue color(default=\"red\")\\n#uicontrol invlerp normalized(range=[0,4096])\\nvoid main(){emitRGBA(vec4(hue*normalized(),1));}',\n",
       "   'shaderControls': {'normalized': {'range': [185, 5032]}},\n",
       "   'name': 'ch0'}],\n",
       " 'layout': '4panel'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuroglancer.viewer_state import ViewerState, CoordinateSpace, ImageLayer\n",
    "\n",
    "state = ViewerState()\n",
    "state.dimensions = CoordinateSpace(\n",
    "    names=['z','y','x','t'], \n",
    "    scales=[5e-7, 2.329612336924942e-7, 2.329612336924942e-7, 1], \n",
    "    units=['m','m','m',''])\n",
    "state.position = [396, 912, 976, 0]\n",
    "state.crossSectionScale = 4.687971627022003\n",
    "state.projectionScale = 2048\n",
    "\n",
    "state.layers.append(\n",
    "    name='ch0',\n",
    "    layer=ImageLayer(\n",
    "        source='zarr://s3://janelia-flylight-imagery-dev/Fly-eFISH/NP01_1_1_SS00790_AstA546_CCHa1_647_1x_LOL.chunked.zarr/0',\n",
    "        layerDimensions=CoordinateSpace(names=[\"c'\"], scales=[1], units=['']),\n",
    "        localPosition=[0],\n",
    "        tab='rendering',\n",
    "        opacity=1,\n",
    "        blend='additive',\n",
    "        shader='#uicontrol vec3 hue color(default=\\\"red\\\")\\n#uicontrol invlerp normalized(range=[0,4096])\\nvoid main(){emitRGBA(vec4(hue*normalized(),1));}',\n",
    "        shaderControls={\n",
    "            'normalized': {\n",
    "                'range': [185, 5032]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "state.layout = '4panel'\n",
    "state.to_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CoordinateSpace({'z': [5e-07, 'm'], 'y': [2.329612336924942e-07, 'm'], 'x': [2.329612336924942e-07, 'm'], 't': [1.0, '']})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimensions': {'z': [5e-07, 'm'],\n",
       "  'y': [2.329612336924942e-07, 'm'],\n",
       "  'x': [2.329612336924942e-07, 'm'],\n",
       "  't': [1.0, '']}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ngview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
